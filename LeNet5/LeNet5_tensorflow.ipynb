{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet5(5层参数可训练)\n",
    "![](https://picgogogo.oss-cn-hangzhou.aliyuncs.com/img/LetNet5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.datasets.mnist as mnist_keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单通道的图片\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "trX = trX.reshape(-1, 28, 28, 1)\n",
    "teX = teX.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化权重的函数\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.random_normal(shape = shape, mean=0, stddev=0.1, dtype=tf.float32))\n",
    "    b = tf.Variable(tf.random_normal(shape=[shape[-1]], mean=0, stddev=0.1, dtype=tf.float32))\n",
    "    return w, b\n",
    "    \n",
    "def get_model(x, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, p_keep_conv):\n",
    "    ## 第一个可训练层， 卷积层\n",
    "    l1 = tf.nn.conv2d(input=x, filter=w1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    l1 = tf.nn.bias_add(l1, b1)\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l1_pool = tf.nn.avg_pool(value=l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    # dropout防止过拟合\n",
    "    l1_pool = tf.nn.dropout(l1_pool, p_keep_conv)\n",
    "    \n",
    "    ## 第二个可训练层，卷积层\n",
    "    l2 = tf.nn.conv2d(input=l1_pool, filter=w2, strides=[1,1,1,1], padding=\"VALID\")\n",
    "    l2 = tf.nn.bias_add(l2, b2)\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    l2_pool = tf.nn.avg_pool(value=l2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    l2_pool = tf.nn.dropout(l2_pool, p_keep_conv)\n",
    "    \n",
    "    # 下面有三层全连接层\n",
    "    fc1 = tf.reshape(l2_pool, [-1, w3.get_shape().as_list()[0]])    # 5 * 5 * 1 * 16\n",
    "    \n",
    "    fc1 = tf.matmul(fc1, w3) + b3\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, p_keep_conv)\n",
    "    \n",
    "    fc2 = tf.matmul(fc1, w4) + b4\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, p_keep_conv)\n",
    "    \n",
    "    fc3 = tf.matmul(fc2, w5) + b5\n",
    "    \n",
    "    return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "w1, b1 = get_weights([5, 5, 1, 6])\n",
    "w2, b2 = get_weights([5, 5, 6, 16])\n",
    "\n",
    "# 全连接层\n",
    "w3, b3 = get_weights([400, 120])\n",
    "w4, b4 = get_weights([120, 84])\n",
    "w5, b5 = get_weights([84, 10])\n",
    "\n",
    "# 参数\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None,10])\n",
    "p_keep_conv = tf.placeholder(tf.float32)\n",
    "epoch = 100\n",
    "\n",
    "pred = get_model(x, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, p_keep_conv)\n",
    "\n",
    "## 定义损失函数， 并指定优化方法\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "train = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "correct = tf.equal(tf.argmax(teY, axis=1), tf.argmax(pred, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        training_batch = zip(range(0, len(trX), 128), range(128, len(trX)+1, 128))\n",
    "        for start, end in training_batch:\n",
    "            t, l = sess.run([train, loss], feed_dict={x:trX[start:end], y:trY[start:end], p_keep_conv:0.7})\n",
    "        \n",
    "        print(\"%d, loss:\" % i, l)\n",
    "    # 准确度\n",
    "    acc = sess.run(accuracy, feed_dict={x:teX, y:teY, p_keep_conv:1})\n",
    "    print(\"准确度：\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowcpu1.14",
   "language": "python",
   "name": "tensorflowcpu1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
